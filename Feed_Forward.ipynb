{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palakagl/DeepLearning/blob/main/Feed_Forward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0azQCVlCiR"
      },
      "source": [
        "# MMAI 894 - Exercise 1\n",
        "## Feedforward artificial neural network : Image classification\n",
        "The goal of this excercise is to show you how to create your first neural network using the tensorflow/keras library. We will be using the MNIST dataset.\n",
        "\n",
        "Submission instructions:\n",
        "- You cannot edit this notebook directly. Save a copy to your drive, and make sure to identify yourself in the title using name and student number\n",
        "- Do not insert new cells before the final one (titled \"Further exploration\") \n",
        "- Verify that your notebook can _restart and run all_. \n",
        "- Select File -> Download as .py (important! not as ipynb)\n",
        "- Rename the file: `studentID_lastname_firstname_ex1.py`\n",
        "- The mark will be assessed on the implementation of the functions with #TODO\n",
        "- **Do not change anything outside the functions**  unless in the further exploration section\n",
        "- The mark is not based on final accuracy - only on correctness\n",
        "- Note: You do not have to answer the questions in thie notebook as part of your submission. They are meant to guide you.\n",
        "\n",
        "- You should not need to use any additional libraries other than the ones listed below. You may want to import additional modules from those libraries, however.\n",
        "\n",
        "References\n",
        "- https://keras.io/getting-started/sequential-model-guide/\n",
        "- https://keras.io/api/utils/python_utils/#to_categorical-function\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "- https://keras.io/api/layers/core_layers/dense/\n",
        "- https://keras.io/api/layers/regularization_layers/dropout/\n",
        "- https://keras.io/api/models/model_training_apis/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp33aomJmJtl"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trOyfziVgETH"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "# Add modules as needed\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For windows laptops add following 2 lines:\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmZEVmTmQGH"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gRy7rVvg_Sl"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    # Import MNIST dataset from openml\n",
        "    dataset = fetch_openml('mnist_784', version=1, data_home=None)\n",
        "\n",
        "    # Data preparation\n",
        "    raw_X = dataset['data']\n",
        "    raw_Y = dataset['target']\n",
        "    return raw_X, raw_Y\n",
        "\n",
        "raw_X, raw_Y = load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEwXHBQh8r93"
      },
      "source": [
        "## Consider the following\n",
        "- what shape is X?\n",
        "- what value ranges does X take? \n",
        " - might this present a problem? \n",
        " - what transformations need to be applied?\n",
        "- what shape is Y?\n",
        "- what value ranges does Y take? \n",
        " - what transformations should be applied?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT499lYakFjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f19a10c-7100-4974-9260-afd93e424805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw_X shape (70000, 784)\n",
            "raw_Y shape (70000,)\n"
          ]
        }
      ],
      "source": [
        "def clean_data(raw_X, raw_Y):\n",
        "    # TODO: clean, QA, and prep raw_X and raw_Y\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    \n",
        "    print(\"raw_X shape\", raw_X.shape)\n",
        "    print(\"raw_Y shape\", raw_Y.shape)\n",
        "\n",
        "  # raw_X = raw_X.values.reshape(raw_X.shape[0], 28, 28 , 1)\n",
        "    cleaned_X = raw_X.astype('float32')/ 255\n",
        "    cleaned_Y = np_utils.to_categorical(raw_Y, 10)\n",
        "\n",
        "    return cleaned_X, cleaned_Y\n",
        "\n",
        "cleaned_X, cleaned_Y = clean_data(raw_X, raw_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpfxuSt4nKUw"
      },
      "source": [
        "#### Data split\n",
        "\n",
        "- Split your data into a train set (50%), validation set (20%) and a test set (30%). You may use scikit-learn's train_test_split function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gjkRpwbkP1j"
      },
      "outputs": [],
      "source": [
        "def split_data(cleaned_X, cleaned_Y):\n",
        "    # TODO: split the data\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    \n",
        "    train_size = 0.5\n",
        "    val_size = 0.2\n",
        "    test_size = 0.3\n",
        "    X_train_val, X_test, X_train_val, Y_test = train_test_split(cleaned_X, cleaned_Y, test_size=test_size, random_state=42)\n",
        "    relative_train_size = train_size / (val_size + train_size)\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, X_train_val, test_size=1-relative_train_size, random_state=42)\n",
        "    \n",
        "    return X_val, X_test, X_train, Y_val, Y_test, Y_train\n",
        "\n",
        "X_val, X_test, X_train, Y_val, Y_test, Y_train = split_data(cleaned_X, cleaned_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHlLLTanrUI"
      },
      "source": [
        "#### [Optional]: plot your data with matplotlib\n",
        "- Hint: you will need to reshape the row's data into a 28x28 matrix\n",
        "- https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html\n",
        "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYpoQEMEkUhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "b30535f4-ed80-4705-f458-de2b660f35db"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-72021a7573d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mviz_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-72021a7573d5>\u001b[0m in \u001b[0;36mviz_data\u001b[0;34m(X_train)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# TODO: (optional) plot your data with matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdigit_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
          ]
        }
      ],
      "source": [
        "def viz_data(X_train):\n",
        "    # TODO: (optional) plot your data with matplotlib\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    digit_image = X_train.iloc[111].values.reshape(28, 28)\n",
        "    plt.imshow(digit_image, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "viz_data(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRTFvCTzn12X"
      },
      "source": [
        "### Model\n",
        "\n",
        "#### Neural network structure\n",
        "- For this network, we'll use 2 hidden layers\n",
        "- Layer 1 should have 128 nodes, a dropout rate of 20%, and relu as its activation function\n",
        "- Layer 2 should have 64 nodes, a dropout rate of 20%, and relu as its activation function\n",
        "- The last layer should map back to the 10 possible MNIST class. Use softmax as the activation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgoOjxY9ki_O"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    # TODO: build the model, \n",
        "    # HINT: you should have Total params: 109,386\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))                            \n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2pi1jVtxbq7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqv4in2ZodVR"
      },
      "source": [
        "# Model compilation\n",
        "\n",
        "- what loss function should you use?\n",
        "- Note your choice of optimizer\n",
        "- Include accuracy as a metric (why are we using accuracy here?)\n",
        "\n",
        "# Model training\n",
        "- Use a batch size of 128, and train for 12 epochs\n",
        "- Use verbose training, include validation data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHD6wIDlk095"
      },
      "outputs": [],
      "source": [
        "def compile_model(model):\n",
        "    # TODO: compile the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
        "    # TODO: train the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    history = model.fit(X_train, Y_train,\n",
        "          batch_size=128, epochs=12,\n",
        "          verbose=2,\n",
        "          validation_data=(X_val, Y_val))\n",
        "    return model, history\n",
        "\n",
        "\n",
        "model = compile_model(model)\n",
        "model, history = train_model(model, X_train, Y_train, X_val, Y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6wzs18_ormL"
      },
      "source": [
        "# Model evaluation\n",
        "- Show the performance on the test set\n",
        "- What is the difference between \"evaluate\" and \"predict\"?\n",
        "- Identify a few images the model classifies incorrectly. Any observations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxrqJb9Uk3Hz"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, X_test, Y_test):\n",
        "    # TODO: evaluate the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
        "\n",
        "    print('Test Accuracy: %.2f' % (test_accuracy*100))\n",
        "    print('Test loss: %.2f' % (test_loss))\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "test_loss, test_accuracy = eval_model(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u21sXyjWpnPX"
      },
      "source": [
        "## Further exploration (Not evaluated)\n",
        "Looking for something else  to do?\n",
        "- Transform your code to do hyperparameter search. \n",
        "- You can vary the number of nodes in the layers, the drop out rate, the optimizer and the parameters in Adam, the batch size, etc.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Feed_Forward.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}